{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8168185,"sourceType":"datasetVersion","datasetId":4833694}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:33:34.788534Z","iopub.execute_input":"2024-04-20T17:33:34.788872Z","iopub.status.idle":"2024-04-20T17:33:35.150716Z","shell.execute_reply.started":"2024-04-20T17:33:34.788844Z","shell.execute_reply":"2024-04-20T17:33:35.149963Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/translation/translation_train.csv') # ,index_col='Language'\ndf.head(10)\ndf.info()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:33:35.152213Z","iopub.execute_input":"2024-04-20T17:33:35.152577Z","iopub.status.idle":"2024-04-20T17:33:35.384302Z","shell.execute_reply.started":"2024-04-20T17:33:35.152553Z","shell.execute_reply":"2024-04-20T17:33:35.383081Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 23406 entries, 0 to 23405\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   English  23406 non-null  object\n 1   Arabic   23406 non-null  object\ndtypes: object(2)\nmemory usage: 365.8+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:33:35.385613Z","iopub.execute_input":"2024-04-20T17:33:35.385999Z","iopub.status.idle":"2024-04-20T17:33:38.653951Z","shell.execute_reply.started":"2024-04-20T17:33:35.385959Z","shell.execute_reply":"2024-04-20T17:33:38.652950Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:33:38.656242Z","iopub.execute_input":"2024-04-20T17:33:38.656666Z","iopub.status.idle":"2024-04-20T17:33:38.665630Z","shell.execute_reply.started":"2024-04-20T17:33:38.656641Z","shell.execute_reply":"2024-04-20T17:33:38.664721Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:59:05.142094Z","iopub.execute_input":"2024-04-20T17:59:05.143071Z","iopub.status.idle":"2024-04-20T17:59:05.149101Z","shell.execute_reply.started":"2024-04-20T17:59:05.143030Z","shell.execute_reply":"2024-04-20T17:59:05.148240Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import unicodedata\nimport regex  # Better support for Unicode regular expressions\n\ndef normalizeArabic(text):\n\n    text = unicodeToAscii(text.lower().strip())\n    # Normalize Arabic characters\n    text = regex.sub(r'[\\p{Mn}\\p{Sk}]+', '', unicodedata.normalize('NFKD', text))\n\n    # Remove non-letter, non-space characters\n    text = regex.sub(r'[^\\p{L}\\s]', '', text)\n\n    # Normalize whitespace\n    text = regex.sub(r'\\s+', ' ', text)\n\n    return text.strip()\n\n# Example usage\narabic_text = \"مرحباً بكم في العالم العربي! %&&\"\nnormalized_text = normalizeArabic(arabic_text)\nprint(normalized_text)  # Output: \"مرحبا بكم في العالم العربي\"","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:59:05.653470Z","iopub.execute_input":"2024-04-20T17:59:05.654145Z","iopub.status.idle":"2024-04-20T17:59:05.661168Z","shell.execute_reply.started":"2024-04-20T17:59:05.654116Z","shell.execute_reply":"2024-04-20T17:59:05.660142Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"مرحبا بكم في العالم العربي\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\n\ndef readLangs(lang1, lang2, reverse=True):\n    print(\"Reading lines...\")\n\n    # Open the CSV file\n    with open('/kaggle/input/translation/translation_train.csv', newline='', encoding='utf-8') as csvfile:\n        # Create a CSV reader object\n        reader = csv.reader(csvfile)\n        \n        # Read the rows of the CSV file\n        lines = [row for row in reader]\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeArabic(s) for s in l] for l in lines]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        print(input_lang)\n        output_lang = Lang(lang1)\n        print(output_lang)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:59:06.164478Z","iopub.execute_input":"2024-04-20T17:59:06.165060Z","iopub.status.idle":"2024-04-20T17:59:06.172989Z","shell.execute_reply.started":"2024-04-20T17:59:06.165033Z","shell.execute_reply":"2024-04-20T17:59:06.171978Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# some filtering based on sentence length and sentence start prefix\nMAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \",\"This\",\"That\"\n)\n\nara_prefixes = ( 'هذه','انا', 'لا')\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes) # turning off filtering \n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:03:55.689485Z","iopub.execute_input":"2024-04-20T18:03:55.689817Z","iopub.status.idle":"2024-04-20T18:03:55.696609Z","shell.execute_reply.started":"2024-04-20T18:03:55.689791Z","shell.execute_reply":"2024-04-20T18:03:55.695693Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def prepareData(lang1, lang2, reverse=True):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(f'input lang is :{input_lang.name}')\n    print(input_lang.name, input_lang.n_words)\n    print(f'output lang is :{output_lang.name}')\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\ninput_lang, output_lang, pairs = prepareData('english', 'arabic', True)\nprint(random.choice(pairs))","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:23:47.538649Z","iopub.execute_input":"2024-04-20T18:23:47.539024Z","iopub.status.idle":"2024-04-20T18:23:51.362467Z","shell.execute_reply.started":"2024-04-20T18:23:47.538995Z","shell.execute_reply":"2024-04-20T18:23:51.361527Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Reading lines...\n<__main__.Lang object at 0x7b84131fa140>\n<__main__.Lang object at 0x7b84131fa1a0>\nRead 23407 sentence pairs\nTrimmed to 316 sentence pairs\nCounting words...\nCounted words:\ninput lang is :arabic\narabic 563\noutput lang is :english\nenglish 402\n['انه وسيم و ذكي', 'he is handsome and clever']\n","output_type":"stream"}]},{"cell_type":"code","source":"# lets take an example\nprint(random.choice(pairs))","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:04:04.404229Z","iopub.execute_input":"2024-04-20T18:04:04.404595Z","iopub.status.idle":"2024-04-20T18:04:04.409403Z","shell.execute_reply.started":"2024-04-20T18:04:04.404567Z","shell.execute_reply":"2024-04-20T18:04:04.408491Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"['سالعب كرة المضرب غدا', 'i am going to play tennis tomorrow']\n","output_type":"stream"}]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:04:09.090738Z","iopub.execute_input":"2024-04-20T18:04:09.091565Z","iopub.status.idle":"2024-04-20T18:04:09.097858Z","shell.execute_reply.started":"2024-04-20T18:04:09.091534Z","shell.execute_reply":"2024-04-20T18:04:09.096909Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n            decoder_outputs.append(decoder_output)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n\n    def forward_step(self, input, hidden):\n        output = self.embedding(input)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.out(output)\n        return output, hidden","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:04:09.783291Z","iopub.execute_input":"2024-04-20T18:04:09.783631Z","iopub.status.idle":"2024-04-20T18:04:09.794328Z","shell.execute_reply.started":"2024-04-20T18:04:09.783606Z","shell.execute_reply":"2024-04-20T18:04:09.793405Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"class BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:04:10.251071Z","iopub.execute_input":"2024-04-20T18:04:10.251431Z","iopub.status.idle":"2024-04-20T18:04:10.258429Z","shell.execute_reply.started":"2024-04-20T18:04:10.251404Z","shell.execute_reply":"2024-04-20T18:04:10.257445Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n        super(AttnDecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention = BahdanauAttention(hidden_size)\n        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None, teacher_forcing_ratio=0.5):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if use_teacher_forcing and target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1)\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach() # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded = self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:04:10.780303Z","iopub.execute_input":"2024-04-20T18:04:10.780653Z","iopub.status.idle":"2024-04-20T18:04:10.793789Z","shell.execute_reply.started":"2024-04-20T18:04:10.780627Z","shell.execute_reply":"2024-04-20T18:04:10.792944Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)\n\ndef get_dataloader(batch_size):\n    input_lang, output_lang, pairs = prepareData('eng', 'ara', True)\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = indexesFromSentence(input_lang, inp)\n        tgt_ids = indexesFromSentence(output_lang, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n\n    train_sampler = RandomSampler(train_data)\n    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n    return input_lang, output_lang, train_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:05:05.522456Z","iopub.execute_input":"2024-04-20T18:05:05.522957Z","iopub.status.idle":"2024-04-20T18:05:05.534355Z","shell.execute_reply.started":"2024-04-20T18:05:05.522911Z","shell.execute_reply":"2024-04-20T18:05:05.533370Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    for data in dataloader:\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:05:06.226641Z","iopub.execute_input":"2024-04-20T18:05:06.226985Z","iopub.status.idle":"2024-04-20T18:05:06.234202Z","shell.execute_reply.started":"2024-04-20T18:05:06.226958Z","shell.execute_reply":"2024-04-20T18:05:06.233175Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:05:06.712593Z","iopub.execute_input":"2024-04-20T18:05:06.713176Z","iopub.status.idle":"2024-04-20T18:05:06.719145Z","shell.execute_reply.started":"2024-04-20T18:05:06.713149Z","shell.execute_reply":"2024-04-20T18:05:06.718151Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if epoch % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n\n        if epoch % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:05:10.289805Z","iopub.execute_input":"2024-04-20T18:05:10.290638Z","iopub.status.idle":"2024-04-20T18:05:10.298725Z","shell.execute_reply.started":"2024-04-20T18:05:10.290608Z","shell.execute_reply":"2024-04-20T18:05:10.297834Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:05:10.534390Z","iopub.execute_input":"2024-04-20T18:05:10.534713Z","iopub.status.idle":"2024-04-20T18:05:10.540518Z","shell.execute_reply.started":"2024-04-20T18:05:10.534689Z","shell.execute_reply":"2024-04-20T18:05:10.539563Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:05:11.011911Z","iopub.execute_input":"2024-04-20T18:05:11.012279Z","iopub.status.idle":"2024-04-20T18:05:11.019147Z","shell.execute_reply.started":"2024-04-20T18:05:11.012251Z","shell.execute_reply":"2024-04-20T18:05:11.018064Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:05:11.357687Z","iopub.execute_input":"2024-04-20T18:05:11.358366Z","iopub.status.idle":"2024-04-20T18:05:11.364368Z","shell.execute_reply.started":"2024-04-20T18:05:11.358338Z","shell.execute_reply":"2024-04-20T18:05:11.363447Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"hidden_size = 256\nbatch_size = 16\n\ninput_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrain(train_dataloader, encoder,decoder, n_epochs = 500, print_every=5, plot_every=5)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:07:15.062341Z","iopub.execute_input":"2024-04-20T18:07:15.063166Z","iopub.status.idle":"2024-04-20T18:10:21.659108Z","shell.execute_reply.started":"2024-04-20T18:07:15.063133Z","shell.execute_reply":"2024-04-20T18:10:21.657896Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Reading lines...\n<__main__.Lang object at 0x7b82e79bf490>\n<__main__.Lang object at 0x7b833c17f850>\nRead 23407 sentence pairs\nTrimmed to 316 sentence pairs\nCounting words...\nCounted words:\nara 563\neng 402\n0m 1s (- 3m 0s) (5 1%) 2.5231\n0m 3s (- 3m 0s) (10 2%) 1.6206\n0m 5s (- 2m 59s) (15 3%) 1.0788\n0m 7s (- 2m 56s) (20 4%) 0.6336\n0m 9s (- 2m 59s) (25 5%) 0.2595\n0m 11s (- 2m 56s) (30 6%) 0.1090\n0m 13s (- 2m 53s) (35 7%) 0.0561\n0m 14s (- 2m 51s) (40 8%) 0.0350\n0m 16s (- 2m 49s) (45 9%) 0.0256\n0m 18s (- 2m 47s) (50 10%) 0.0263\n0m 20s (- 2m 44s) (55 11%) 0.0174\n0m 22s (- 2m 43s) (60 12%) 0.0137\n0m 24s (- 2m 41s) (65 13%) 0.0144\n0m 25s (- 2m 39s) (70 14%) 0.0119\n0m 27s (- 2m 37s) (75 15%) 0.0113\n0m 29s (- 2m 35s) (80 16%) 0.0103\n0m 31s (- 2m 33s) (85 17%) 0.0093\n0m 33s (- 2m 31s) (90 18%) 0.0091\n0m 35s (- 2m 29s) (95 19%) 0.0088\n0m 36s (- 2m 27s) (100 20%) 0.0082\n0m 38s (- 2m 25s) (105 21%) 0.0087\n0m 40s (- 2m 23s) (110 22%) 0.0078\n0m 42s (- 2m 22s) (115 23%) 0.0069\n0m 44s (- 2m 20s) (120 24%) 0.0082\n0m 46s (- 2m 18s) (125 25%) 0.0077\n0m 47s (- 2m 16s) (130 26%) 0.0073\n0m 49s (- 2m 14s) (135 27%) 0.0071\n0m 51s (- 2m 12s) (140 28%) 0.0073\n0m 53s (- 2m 10s) (145 28%) 0.0069\n0m 55s (- 2m 9s) (150 30%) 0.0130\n0m 57s (- 2m 7s) (155 31%) 0.0564\n0m 58s (- 2m 5s) (160 32%) 0.0081\n1m 0s (- 2m 3s) (165 33%) 0.0094\n1m 2s (- 2m 1s) (170 34%) 0.0081\n1m 4s (- 1m 59s) (175 35%) 0.0074\n1m 6s (- 1m 57s) (180 36%) 0.0071\n1m 8s (- 1m 56s) (185 37%) 0.0067\n1m 9s (- 1m 54s) (190 38%) 0.0062\n1m 11s (- 1m 52s) (195 39%) 0.0072\n1m 13s (- 1m 50s) (200 40%) 0.0062\n1m 15s (- 1m 48s) (205 41%) 0.0056\n1m 17s (- 1m 46s) (210 42%) 0.0058\n1m 19s (- 1m 44s) (215 43%) 0.0067\n1m 20s (- 1m 42s) (220 44%) 0.0060\n1m 22s (- 1m 41s) (225 45%) 0.0062\n1m 24s (- 1m 39s) (230 46%) 0.0055\n1m 26s (- 1m 37s) (235 47%) 0.0070\n1m 28s (- 1m 35s) (240 48%) 0.0062\n1m 30s (- 1m 33s) (245 49%) 0.0062\n1m 31s (- 1m 31s) (250 50%) 0.0074\n1m 33s (- 1m 30s) (255 51%) 0.0064\n1m 35s (- 1m 28s) (260 52%) 0.0064\n1m 37s (- 1m 26s) (265 53%) 0.0054\n1m 39s (- 1m 24s) (270 54%) 0.0059\n1m 41s (- 1m 22s) (275 55%) 0.0059\n1m 42s (- 1m 20s) (280 56%) 0.0059\n1m 44s (- 1m 18s) (285 56%) 0.0055\n1m 46s (- 1m 17s) (290 57%) 0.0061\n1m 48s (- 1m 15s) (295 59%) 0.0060\n1m 50s (- 1m 13s) (300 60%) 0.0066\n1m 51s (- 1m 11s) (305 61%) 0.0058\n1m 53s (- 1m 9s) (310 62%) 0.0054\n1m 55s (- 1m 7s) (315 63%) 0.0066\n1m 57s (- 1m 6s) (320 64%) 0.0061\n1m 59s (- 1m 4s) (325 65%) 0.0066\n2m 0s (- 1m 2s) (330 66%) 0.0056\n2m 2s (- 1m 0s) (335 67%) 0.0067\n2m 4s (- 0m 58s) (340 68%) 0.0061\n2m 6s (- 0m 56s) (345 69%) 0.0064\n2m 8s (- 0m 54s) (350 70%) 0.0069\n2m 9s (- 0m 53s) (355 71%) 0.0053\n2m 11s (- 0m 51s) (360 72%) 0.0062\n2m 13s (- 0m 49s) (365 73%) 0.0065\n2m 15s (- 0m 47s) (370 74%) 0.0055\n2m 17s (- 0m 45s) (375 75%) 0.0064\n2m 18s (- 0m 43s) (380 76%) 0.0058\n2m 20s (- 0m 42s) (385 77%) 0.0060\n2m 22s (- 0m 40s) (390 78%) 0.0057\n2m 24s (- 0m 38s) (395 79%) 0.0049\n2m 26s (- 0m 36s) (400 80%) 0.0058\n2m 28s (- 0m 34s) (405 81%) 0.0063\n2m 29s (- 0m 32s) (410 82%) 0.0061\n2m 31s (- 0m 31s) (415 83%) 0.0062\n2m 33s (- 0m 29s) (420 84%) 0.0056\n2m 35s (- 0m 27s) (425 85%) 0.0067\n2m 37s (- 0m 25s) (430 86%) 0.0065\n2m 38s (- 0m 23s) (435 87%) 0.0064\n2m 40s (- 0m 21s) (440 88%) 0.0065\n2m 42s (- 0m 20s) (445 89%) 0.0061\n2m 44s (- 0m 18s) (450 90%) 0.0064\n2m 46s (- 0m 16s) (455 91%) 0.0062\n2m 47s (- 0m 14s) (460 92%) 0.0513\n2m 49s (- 0m 12s) (465 93%) 0.1328\n2m 51s (- 0m 10s) (470 94%) 0.0165\n2m 53s (- 0m 9s) (475 95%) 0.0065\n2m 55s (- 0m 7s) (480 96%) 0.0072\n2m 57s (- 0m 5s) (485 97%) 0.0073\n2m 58s (- 0m 3s) (490 98%) 0.0060\n3m 0s (- 0m 1s) (495 99%) 0.0057\n3m 2s (- 0m 0s) (500 100%) 0.0057\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\nevaluateRandomly(encoder, decoder)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:10:24.353863Z","iopub.execute_input":"2024-04-20T18:10:24.354510Z","iopub.status.idle":"2024-04-20T18:10:24.423112Z","shell.execute_reply.started":"2024-04-20T18:10:24.354478Z","shell.execute_reply":"2024-04-20T18:10:24.422264Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"> هن اخواتي\n= they are my sisters\n< they are my sisters <EOS>\n\n> حظه يسبق ذكاءه\n= he is more lucky than clever\n< he is more lucky than clever <EOS>\n\n> انك لست طالبا\n= you are not a student\n< you are not a student <EOS>\n\n> تقول انك تتعمد اخفاء مظهرك الحسن\n= you are saying you intentionally hide your good looks\n< you are saying you intentionally hide your good looks <EOS>\n\n> انه قلق بسبب مرض والده\n= he is concerned about his fathers illness\n< he is concerned about his fathers illness <EOS>\n\n> انت امي\n= you are my mother\n< you are my mother <EOS>\n\n> تحبني كل عايلتي\n= i am loved by all my family\n< i am loved by all my family <EOS>\n\n> انا من الاكوادور\n= i am from ecuador\n< i am from ecuador <EOS>\n\n> هو رجل حكمة\n= he is a man of wit\n< he is a man of wit <EOS>\n\n> انت لست مسوولا عن تلك الفوضى\n= you arent responsible for that mess\n< you arent responsible for that mess <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\nevaluateRandomly(encoder, decoder)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:34:45.894739Z","iopub.execute_input":"2024-04-20T17:34:45.895333Z","iopub.status.idle":"2024-04-20T17:34:45.964908Z","shell.execute_reply.started":"2024-04-20T17:34:45.895303Z","shell.execute_reply":"2024-04-20T17:34:45.964016Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"> i dont think tom would want to do that\n= لا اظنن توم يريد فعل ذلك\n< لا اظنن توم يريد فعل ذلك <EOS>\n\n> i read his book\n= انا اقرا كتابه\n< انا اقرا كتابه على الاطلاق <EOS>\n\n> im sure that she will come back soon\n= انا متاكد من انها ستعود قريبا\n< انا متاكد من انها ستعود قريبا <EOS>\n\n> im serious\n= انا لا امزح\n< انا لا احاول ان <EOS>\n\n> im really hungry\n= انا جايع جدا\n< انا جايع جدا في الصباح <EOS>\n\n> i cant see anything\n= لا ارى شييا\n< لا استطيع ابتكار ارى <EOS>\n\n> im trying to sleep\n= انا احاول ان انام\n< انا احاول ان انام احاول <EOS>\n\n> no one shall be arbitrarily deprived of his property\n= لا يجوز تجريد احد من ملكه تعسفا\n< لا يجوز تجريد احد من ملكه تعسفا <EOS>\n\n> i like animals for example cats and dogs\n= انا احب الحيوانات على سبيل المثال القطط والكلاب\n< انا احب الحيوانات على سبيل المثال القطط والكلاب <EOS>\n\n> i dont know when hell be here\n= لا اعرف متى سيكون هنا\n< لا اعرف متى سيكون هنا <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save encoder\ntorch.save(encoder.state_dict(), './ara_encoder.pth')\n\n# Save decoder\ntorch.save(decoder.state_dict(), './ara_decoder.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T18:12:17.095651Z","iopub.execute_input":"2024-04-20T18:12:17.096015Z","iopub.status.idle":"2024-04-20T18:12:17.114788Z","shell.execute_reply.started":"2024-04-20T18:12:17.095988Z","shell.execute_reply":"2024-04-20T18:12:17.113997Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"encoder.load_state_dict(torch.load('./eng_to_ara_encoder.pth'))\ndecoder.load_state_dict(torch.load('./eng_to_ara_decoder.pth'))\n\ndef evaluateOneSentence(encoder, decoder, sentence, input_lang, output_lang):\n    print('>', sentence)\n    output_words, _ = evaluate(encoder, decoder, sentence, input_lang, output_lang)\n    output_sentence = ' '.join(output_words)\n    print('<', output_sentence)\n\n# Example usage:\ninput_lang, output_lang, pairs = prepareData('english', 'arabic', False)\nencoder = encoder # initialize your encoder\ndecoder = decoder # initialize your decoder\n# input_sentence = \"انا لا اشعر بالعطش\"\ninput_sentence = \"know what\"\nevaluateOneSentence(encoder, decoder, input_sentence, input_lang, output_lang)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:34:40.863257Z","iopub.status.idle":"2024-04-20T17:34:40.863601Z","shell.execute_reply.started":"2024-04-20T17:34:40.863440Z","shell.execute_reply":"2024-04-20T17:34:40.863454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\ndef evaluate(encoder, decoder, sentence, input_lang, output_lang):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn\n\ndef evaluateRandomly(encoder, decoder, n=10):\n    references = []  # List to store reference translations\n    candidates = []  # List to store candidate translations\n    \n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')\n        \n        references.append(pair[1].split())  # Add reference translation to references list\n        candidates.append(output_words[:-1])  # Remove <EOS> token from candidate translation and add to candidates list\n    \n    # Calculate BLEU score with smoothing function\n    smoothing_function = SmoothingFunction().method4\n    bleu_score = nltk.translate.bleu_score.corpus_bleu(references, candidates)\n    print(\"BLEU Score:\", bleu_score)\n\nencoder.eval()\ndecoder.eval()\nevaluateRandomly(encoder, decoder)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:34:40.865293Z","iopub.status.idle":"2024-04-20T17:34:40.865631Z","shell.execute_reply.started":"2024-04-20T17:34:40.865470Z","shell.execute_reply":"2024-04-20T17:34:40.865484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\ndef evaluateSpecificSentence(encoder, decoder, sentence, input_lang, output_lang):\n    print('>', sentence)\n    output_words, _ = evaluate(encoder, decoder, sentence, input_lang, output_lang)\n    output_sentence = ' '.join(output_words)\n    print('<', output_sentence)\n    print('')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:45:56.017254Z","iopub.execute_input":"2024-04-20T17:45:56.017908Z","iopub.status.idle":"2024-04-20T17:45:56.022905Z","shell.execute_reply.started":"2024-04-20T17:45:56.017880Z","shell.execute_reply":"2024-04-20T17:45:56.021985Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\nevaluateSpecificSentence(encoder, decoder,\"no please\",input_lang,output_lang)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T17:46:06.213324Z","iopub.execute_input":"2024-04-20T17:46:06.214150Z","iopub.status.idle":"2024-04-20T17:46:06.227908Z","shell.execute_reply.started":"2024-04-20T17:46:06.214117Z","shell.execute_reply":"2024-04-20T17:46:06.226928Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"> no please\n< لا يوجد احد من ملكه <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}